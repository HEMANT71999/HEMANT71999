### Hi there, I'm Hemant Jain 👋

I’m a **Cloud Data Engineer** with extensive experience building scalable data pipelines, data lakes, and event-driven architectures across **AWS** and **Azure**. My focus is on optimizing ETL/ELT pipelines, implementing data lakehouses using **Medallion Architecture**, and leveraging **Apache Spark** for both batch and real-time data processing. I’m passionate about delivering innovative data solutions that drive business insights and enable data-driven decision-making.

#### 🚀 **Current Work**
- 🔭 Currently working on building and optimizing **cloud-based data pipelines** using **Azure Data Factory**, **Databricks**, and **Azure Synapse Analytics** to process and transform both structured and unstructured data at scale.
- Implementing **Medallion Architecture** in **Azure Data Lake** to build scalable, high-performance **data lakehouses** for optimized data storage and processing.
- Designing **real-time data streaming** solutions with **Azure Stream Analytics** and **Databricks**, providing near-instant insights and analytics.
- Focusing on **ETL/ELT pipeline optimization**, enhancing data flow automation with **Apache Airflow** and improving resource utilization in cloud environments.

#### 🌱 **Learning and Development**
- 🌱 Deepening my skills in **Azure Data Factory** for data integration, **Databricks** for big data processing, and **Apache Spark** for both batch and streaming data solutions.
- Continuously learning about **cloud-based data architectures** (e.g., **Azure Synapse Analytics**, **Delta Lake**) to design optimized data lakes and warehouses.
- Expanding knowledge in **data security** practices and **compliance** for cloud data solutions, with a focus on scalable data pipeline management and automation.


#### 💬 **Ask Me About**
- Cloud Platforms: **AWS**, **Azure**
- Big Data Technologies: **Apache Spark**, **Kafka**, **Databricks**, **AWS Kinesis**, **Snowflake**
- Data Integration: **ETL/ELT pipelines**, **Medallion Architecture**, **AWS Glue**, **Azure Data Factory**
- Programming: **Python**, **PySpark**, **SQL**, **Bash**, **Scala**
- DevOps and Automation: **Docker**, **Kubernetes**, **Jenkins**
- Data Warehousing: **Redshift**, **Snowflake**, **Kimball Methodology**
- Data Security and Compliance: Ensuring secure and compliant data handling

#### 📚 **Work Experience**

- **Data Engineer** at **Lingaro** (July 2024 – Present)  
  Location: India  
  - Designed scalable cloud-based data processing pipelines on **Azure**, processing structured, semi-structured, and unstructured data.
  - Implemented **Medallion Architecture** in **Azure Data Lake** to build scalable data lakehouses, optimizing storage and query performance.
  - Developed **real-time streaming solutions** with **Azure Stream Analytics** and **Databricks**, delivering actionable insights for business stakeholders.
  - Optimized **Apache Spark** jobs, boosting performance by 25% through advanced optimization techniques.

- **Cloud Data Engineer** at **Squadron Technology** (January 2023 – June 2024)  
  Location: India  
  - Engineered and managed scalable data pipelines across **AWS** and **Azure**, integrating multiple data sources using **AWS Glue**, **Lambda**, and **Kinesis**.
  - Designed real-time streaming pipelines with **AWS Kinesis** and **Lambda**, enabling real-time data analysis.
  - Migrated data from **MongoDB** to **Redshift** and implemented **Change Data Capture (CDC)** for real-time data replication.
  - Reduced processing times by 30% by optimizing **Apache Spark** jobs and enhancing resource utilization.

- **Python Developer** at **Quantum IT Innovation** (April 2023 – October 2023)  
  Location: India  
  - Developed **web scraping** solutions with **Selenium** and **Python** to extract and load data into databases for analytics and reporting.
  - Built a **machine learning model** to detect anomalies in video streams, classifying patterns for **anomaly detection**.

- **Trainee Data Engineer** at **Searce** (July 2021 – March 2022)  
  Location: India  
  - Assisted in the development of **data pipelines** on **Google Cloud Platform (GCP)** using **DataFlow** and **Agent Builder**.
  - Integrated and processed data across multiple **GCP services**, ensuring optimal data storage and security.

---

#### 🎓 **Education**
- **B.Tech in Computer Science** from **Teerthanker Mahaveer University** (August 2018 – July 2022)

---

#### 🌐 **Languages**
- **English** (Fluent)
- **Hindi** (Native)

---

#### 📞 **How to Reach Me**
- 📧 **Email**: [Jainhemant81079@gmail.com](mailto:Jainhemant81079@gmail.com)

---

#### 😄 **Fun Fact**
- I enjoy experimenting with **new technologies** and building **Data Pipeline** in my free time. When not working on data engineering projects, I like to explore creative coding challenges and contribute to open-source projects!
